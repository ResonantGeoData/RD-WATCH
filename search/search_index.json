{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RD-WATCH Documentation","text":"<p>RDWATCH (ResonantGeoData WATCH) is a modern web application that offers easy access to a wide range of remote sensing imagery, as well as AI-generated outputs, to aid in the detection of global scale changes. RDWATCH enhances the AI workflow by providing monitoring, annotation, and visualization capabilities within a geospatial context. The web interface of RDWATCH prioritizes a higly ergononmic user experience and application performance for different user groups, including analysts, annotators, and algorithm developers. It enables analysts to thoroughly examine model outputs, allows annotators to work within a geospatial context, and assists developers in comparing results with ground truth to identify potential model failures.</p> <p></p> <p>RDWATCH is maintained and supported by Kitware.</p>"},{"location":"#rdwatch-features","title":"RDWATCH Features","text":""},{"location":"#for-developers","title":"For Developers","text":"<ul> <li> <p>Scalable and Modular Architecture: Built on top of the widely used Django web framework and open source geospatial technologies in an architecture that is flexible and extensible.</p> </li> <li> <p>Efficient Data Management: Domain-specific data models enable fast search across data types.</p> </li> <li> <p>Advanced Technology Stack: Supports dynamic vector tiles, open standards like STAC, and open-source software (MapLibre, Vue.js) on AWS for scalability.</p> </li> </ul>"},{"location":"#for-annotators-and-analysts","title":"For Annotators and Analysts","text":"<ul> <li> <p>Enhanced Workflow: Provides interfaces for efficient monitoring, annotation, and visualization of geospatial data.</p> </li> <li> <p>Interactive Visualizations: Dynamic observation of data changes over time, directly in the web interface, enhancing the annotation process.</p> </li> <li> <p>Exporting Capabilities: Easily export model outputs and imagery, facilitating collaboration and sharing in formats like GIF and GeoJSON.</p> </li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li> <p>Development</p> </li> <li> <p>Data Ingestion</p> </li> </ul>"},{"location":"#related-work","title":"Related Work","text":"<ul> <li>Danesfield</li> </ul>"},{"location":"#acknowledgement","title":"Acknowledgement","text":"<p>This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), 6 Intelligence Advanced Research Projects Activity (IARPA), via 2021-2011000005. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes, notwithstanding any copyright annotation therein.</p> <p>For more information, visit RDWATCH on GitHub.</p>"},{"location":"IQR/","title":"Iterative Query Refinement","text":""},{"location":"IQR/#getting-started-locally","title":"Getting Started Locally","text":""},{"location":"IQR/#initial-iqr-data","title":"Initial IQR Data","text":"<p>To avoid generating the IQR mappings from scratch, you should have a <code>iqr-data.tar.gz</code> file with the following contents:</p> <pre><code>models/\n    faiss_index_params.json\n    faiss_index\nsites/\n    *.geojson\nworkdir/\n    data.memorySet.pickle\n    descriptor_set.pickle\n    idx2uid.mem_kvstore.pickle\n    uid2idx.mem_kvstore.pickle\n</code></pre> <p>Extract <code>iqr-data.tar.gz</code> to a suitable location. We will refer to it as <code>/path/to/iqr-data</code> from here on out.</p>"},{"location":"IQR/#docker-compose-volumes","title":"Docker Compose Volumes","text":"<p>Edit the <code>iqr_rest</code> service in <code>docker-compose.override.yaml</code>. Specifically, the volumes must be updated with the following mounts. These are commented accordingly in the <code>docker-compose.override.yaml</code> file.</p> <p>IMPORTANT: Replace the <code>/path/to/iqr-data</code> path prefix with the correct path.</p> <ul> <li><code>/path/to/iqr-data/workdir:/iqr/workdir</code></li> <li><code>/path/to/iqr-data/models:/iqr/models</code></li> </ul>"},{"location":"IQR/#ingesting-the-sites","title":"Ingesting The Sites","text":"<p>First, start the docker services and perform the requisite migrations and setup.</p> <pre><code>docker compose up -d\ndocker compose run --rm django poetry run django-admin migrate\ndocker compose run --rm django poetry run django-admin createsuperuser\ndocker compose run --rm django poetry run django-admin loaddata lookups\n</code></pre> <p>Now, we can ingest the sites provided in the IQR data archive. The following snippet assumes a bash shell currently located in the RD-WATCH repo root.</p> <p>IMPORTANT: Replace the <code>/path/to/iqr-data</code> path prefix with the correct path.</p> <pre><code>for region in \"KR_R001\" \"KR_R002\" \"CH_R001\" \"NZ_R001\"\ndo\n  python ./scripts/loadModelRun.py \"$region\" \"/path/to/iqr-data/sites/${region}_*.geojson\" --title \"$region\" --performer_shortcode TE\ndone\n</code></pre>"},{"location":"IQR/#loading-the-worldview-images","title":"Loading The WorldView Images","text":"<p>To ensure that the IQR query results have an associated image, open the RD-WATCH interface in the browser and download the \"WV\" satellite chips for every model run. This may take a long time!</p>"},{"location":"IQR/#running-iqr-through-rd-watch","title":"Running IQR through RD-WATCH","text":"<ol> <li>Navigate to http://localhost:8080/#/iqr to enable IQR.</li> <li> <p>Select a model run, and then select a site. If the site has IQR enabled, then there will be an IQR button (as shown below). Clicking this button will initiate an IQR query on that site, and a right sidebar will show up with the results.</p> <p></p> </li> <li> <p>IQR refinement occurs in two steps:</p> </li> <li>Update positive, neutral, and negative results in the IQR result listing.</li> <li>Run \"Refine Query\" to generate a new list of IQR results.</li> </ol>"},{"location":"DevDocs/Architecture/","title":"Architecture","text":""},{"location":"DevDocs/Architecture/#overview","title":"Overview","text":"<p>The basic RDWATCH systems is based on utilizing docker containers to create a full contained application for local development and deployment.</p> <ul> <li>Django is used as the back-end ORM with Postgres/PostGIS as a database.  There are multiple Django apps.  One for base RDWATCH and one for the Scoring data.</li> <li>Celery is used to execute and manage long running tasks.</li> <li>MinIO/S3 is used as object storage for cropped/chipped satellite images.</li> <li>Vue based front-end utilizing Vuetify for components and Maplibre for vector tile rendering</li> </ul>"},{"location":"DevDocs/Architecture/#django-overview","title":"Django Overview","text":""},{"location":"DevDocs/Architecture/#core","title":"Core","text":"<p>This is the base application for RDWATCH.  All endpoints that don't contain <code>api/v1/scoring/*</code> will utilize the base Core Application. This is also the mode location for all satellite image storage and downloading progress.</p>"},{"location":"DevDocs/Architecture/#scoring","title":"Scoring","text":"<p>When the Environment Variable <code>RDWATCH_POSTGRESQL_SCORING_URI</code> is set the system expects to be connected to a second Database.  This database is based of the T&amp;E metrics scoring database.  The RDWATCH team doesn't have direct control over the schema of this database so any data that is modified or stored should be placed in the RDWATCH database (This includes data like Stored Satellite Images or downloading progress).</p> <p>For reading from the database Django Models are created but the <code>managed</code> property in the <code>Meta</code> class is set to False.  This allows for reading from the database using similar django querysets and orm logic while not having django actively manage the system.  This means that when the DB changes the models need to be updated.</p> <p>The standard <code>rdwatch/core/views</code> endpoints for visualizing model-runs, sites, siteobservations are all mirrored in the Scoring application so they can access information directly from the scoring database.</p>"},{"location":"DevDocs/Architecture/#tasks","title":"Tasks","text":"<p>Each app core and scoring has it's own tasks used in celery.  These are tasks that will download GeoJSON for an entire model run as well as downloading satellite images.  All information regarding satellite images are stored in the core rdwatch database because this project doesn't have access to modify the scoring database.</p>"},{"location":"DevDocs/Architecture/#stack-links","title":"Stack Links","text":""},{"location":"DevDocs/Architecture/#django","title":"Django","text":"<p>A single Django application (<code>rdwatch</code>) for the backend. Source code is in the \"rdatch\" folder.</p> <ul> <li>Django with GeoDjango</li> <li>Django Ninja</li> <li>Poetry for dependency management</li> </ul>"},{"location":"DevDocs/Architecture/#vue","title":"Vue","text":"<p>The Vue-based SPA frontend. Source code is in the \"vue\" folder.</p> <ul> <li>Vue 3</li> <li>Vuetify</li> <li>MapLibre GL JS</li> <li>npm for dependency management</li> </ul>"},{"location":"DevDocs/Architecture/#services","title":"Services","text":"<p>Services the application requires.</p> <ul> <li>NGINX Unit: serves both the Django application backend and the bundled static assets from the Vue frontend</li> <li>PostgreSQL and PostGIS: the RDWATCH database</li> <li>Redis: caching and a job queue for celery</li> <li>MinIO/S3: storage for satellite images for faster browsing</li> <li>Celery: long running tasks for image chipping, downloading and compressing geoJSONs.</li> </ul>"},{"location":"DevDocs/GettingStarted/","title":"Getting Started","text":"<p>This document gives an overview of the code contained in this monorepo and the recommended development setup.</p>"},{"location":"DevDocs/GettingStarted/#develop-with-docker-recommended","title":"Develop with Docker (recommended)","text":"<p>This is the simplest configuration for developers to start with.</p> <ol> <li>Make a copy of <code>template.env</code> and call it <code>.env</code>.</li> <li>Set the environment variables in <code>.env</code>.</li> <li>Run <code>docker compose up</code> to start the Django development server and Celery worker, plus all backing services    like PostGIS, Redis, RabbitMQ, etc.</li> <li>Run <code>docker compose run --rm django poetry run django-admin migrate</code> to apply database migrations.</li> <li>Run <code>docker compose run --rm django poetry run django-admin loaddata lookups</code> to initialize your database with required data.</li> <li>Optionally, create an account for the Django admin (http://localhost:8000/admin) by running <code>docker compose run --rm django poetry --directory django run django-admin createsuperuser</code></li> <li>If running the docker compose by default a client development server should be started at http://localhost:8080/</li> <li>On first login you will be redirected to the <code>Adminstrator</code> page.  This is for logging in.  Afterwards you should be able to redirect back to either http://localhost:8080/ or http://localhost:3000/.  The deployed version will automatically redirect.</li> <li>If doing local Client Development, start the client development server:    <pre><code>cd vue\nnpm install\nnpm run dev\n</code></pre>    The server will be started at http://localhost:3000 as to not conflict with the docker compose development service    When finished, use <code>Ctrl+C</code></li> </ol>"},{"location":"DevDocs/GettingStarted/#develop-natively","title":"Develop Natively","text":"<p>This configuration still uses Docker to run attached services in the background, but allows developers to run Python code on their native system.</p>"},{"location":"DevDocs/GettingStarted/#initial-setup","title":"Initial Setup","text":"<ol> <li>Make a copy of <code>template.env</code> and call it <code>.env</code>.</li> <li>Set the environment variables in <code>.env</code>.</li> <li>Run <code>docker compose -f ./docker-compose.yaml up -d</code></li> <li>Install Python 3.11</li> <li>Install    <code>psycopg2</code> build prerequisites</li> <li>Install Poetry</li> <li>Run <code>poetry --directory django install</code></li> <li>Run the following command to configure your environment: <code>source ./dev/export-env.sh dev/.env.docker-compose-native ./dev/export-env.sh .env</code></li> <li>Optionally, create an account for the Django admin (http://localhost:8000/admin) by running <code>poetry --directory django run django-admin createsuperuser</code></li> </ol>"},{"location":"DevDocs/GettingStarted/#run-application","title":"Run Application","text":"<ol> <li>Ensure <code>docker compose -f ./docker-compose.yaml up -d</code> is still active</li> <li>Run:</li> <li><code>source ./dev/export-env.sh dev/.env.docker-compose-native</code></li> <li><code>source ./dev/export-env.sh .env</code></li> <li><code>poetry run --directory django django/src/manage.py migrate</code></li> <li><code>poetry run --directory django django/src/manage.py loaddata lookups</code></li> <li><code>poetry run --directory django django/src/manage.py runserver</code></li> <li>Run in a separate terminal:</li> <li><code>source ./dev/export-env.sh</code></li> <li><code>poetry run --directory django celery --app rdwatch.celery worker --loglevel INFO --without-heartbeat</code></li> <li>Run in another separate terminal:</li> <li><code>source ./dev/export-env.sh</code></li> <li><code>poetry run --directory django celery --app rdwatch.celery beat --loglevel INFO</code></li> <li>When finished, run <code>docker compose stop</code></li> <li>To destroy the stack and start fresh, run <code>docker compose down</code></li> <li>Note: this command does not destroy docker volumes, such as those associated with the postgresql and minio services. To destroy those as well, run <code>docker compose down -v</code>.</li> </ol>"},{"location":"DevDocs/GettingStarted/#a-note-on-database-migrations","title":"A note on database migrations","text":"<p>Note that database migrations are not run automatically. Anytime a new migration is introduced, you must run the following command to apply it:</p> <p><code>poetry --directory django run django-admin migrate</code></p>"},{"location":"DevDocs/GettingStarted/#type-support-for-vue-imports-in-vs-code","title":"Type support for \".vue\" imports in VS Code","text":"<p>Enable \"takeover mode\" for Volar.</p> <ol> <li>Disable built-in TypeScript extension:</li> <li>Open the Command Palette (\u2318 \u21e7 P or Ctrl Shift P) and run <code>&gt;Extensions: Show Built-in Extensions</code> command</li> <li>Find \"TypeScript and JavaScript Language Features\", right click and select \"Disable (Workspace)\"</li> <li>Reload VS Code</li> </ol>"},{"location":"DevDocs/GettingStarted/#stack","title":"Stack","text":"<p>The key software used to build the application.</p>"},{"location":"DevDocs/GettingStarted/#django","title":"Django","text":"<p>A single Django application (<code>rdwatch</code>) for the backend. Source code is in the \"django\" folder.</p> <ul> <li>Django 4 with GeoDjango</li> <li>Django Ninja</li> <li>Poetry for dependency management</li> </ul>"},{"location":"DevDocs/GettingStarted/#vue","title":"Vue","text":"<p>The Vue-based SPA frontend. Source code is in the \"vue\" folder.</p> <ul> <li>Vue 3</li> <li>Vuetify</li> <li>MapLibre GL JS</li> <li>npm for dependency management</li> </ul>"},{"location":"DevDocs/GettingStarted/#services","title":"Services","text":"<p>Services the application requires.</p> <ul> <li>NGINX Unit: serves both the backend and the bundled static assets</li> <li>PostgreSQL and PostGIS: data warehouse</li> <li>MinIO/S3: storage for satellite images for faster browsing</li> <li>Redis: caching and job queue</li> </ul>"},{"location":"DevDocs/GettingStarted/#ingesting-data","title":"Ingesting Data","text":""},{"location":"DevDocs/GettingStarted/#loading-ground-truth-data","title":"Loading Ground Truth Data","text":"<p>Within the ./scripts directory is a python script named <code>loadGroundTruth.py</code>.  This file can be used in conjunction with the ground truth annotaitons located in the annotation Repo: Annotation Repo Running a command like <code>python loadGroundTruth.py ~/AnnotationRepoLocation --skip_region</code> will load all of the annotations for the ground truth while skipping the regions.</p>"},{"location":"DevDocs/GettingStarted/#loading-single-model-runs","title":"Loading Single Model Runs","text":"<p>Within the ./scripts directory is a python script named <code>loadModelRuns.py</code>.  This can be used to load a folder filled with geojson data into the system by using a command like:</p> <p><pre><code>python loadModelRuns.py 'KR_0001' \"./site_models/KR_R001_*.geojson\" --title Test_Eval_12 --performer_shortcode 'KIT' --eval_num 12 --eval_run_num 0\n</code></pre> Within this python file at the top is the rgd_endpoint variable which needs to be set to the server URL and port for where RGD is hosted.  By default this assumes running locally with <code>http://localhost:8000</code> Be sure that the system is up and running before running the commands. The above command will load the data in the site_models/KR_R001 files and give it the title 'Test_Eval_12'.  The eval_num and eval_run_num aren't required unless the scoring database is going to be connected to the system.  Within the script there is</p>"},{"location":"DevDocs/GettingStarted/#scoring","title":"Scoring","text":"<p>The Metrics and Test Framework can be used in addition with RGD to display scores from results. In development mode a scoring Database is automatically initialized at URI: <code>postgresql+psycopg2://scoring:secretkey@localhost:5433/scoring</code></p> <p>To score data: - Clone the Metrics and Test Framework repo. - In the Metrics and Test Framework repo:   - Copy the <code>alembic_example.ini</code> to <code>alembic.ini</code> and set the <code>sqlalchemy.url = postgresql+psycopg2://scoring:secretkey@localhost:5433/scoring</code>   - Run <code>pip install -e .</code> to install the metrics-and-test-framework package   - Run <code>alembic upgrade head</code> to initialize the scoring database schema   - Execute the scoring code from inside the metrics and test framework: <pre><code>  python -m iarpa_smart_metrics.run_evaluation \\\n               --roi KR_R001 \\\n               --gt_dir ../annotations/site_models/ \\\n               --rm_path ../KR_R001/region_model.geojson \\\n               --sm_dir ../KR_R001/site_models/ \\\n               --output_dir ../KR_R001/output \\\n               --eval_num 12 \\\n               --eval_run_num 0 \\\n               --performer kit \\\n               --no-viz \\\n               --no-viz-detection-table \\\n               --no-viz-comparison-table \\\n               --no-viz-associate-metrics \\\n               --no-viz-activity-metrics \\\n               --sequestered_id KR_R001 \\\n               --db_conn_str postgresql+psycopg2://scoring:secretkey@localhost:5433/scoring\n</code></pre> - the rm_path and sm_dir shgould be your test annotaitons. - gt annotations can be retrieved from the Annotation Repo - be sure to set the val_num and eval_run_num and remember them when ingesting data into RGD.  The region, eval_num, eval_run_num and performer are used to connect data loaded in RGD to the scoring data.</p>"},{"location":"DevDocs/IngestingData/","title":"Ingesting Data","text":""},{"location":"DevDocs/IngestingData/#ingesting-data","title":"Ingesting Data","text":""},{"location":"DevDocs/IngestingData/#rdwatch_model_run_api_key","title":"RDWATCH_MODEL_RUN_API_KEY","text":"<p>Check the <code>./dev/.env.docker-compose</code> environment file or the <code>.env</code> file in the root of the repository for the presence of the <code>RDWATCH_MODEL_RUN_API_KEY</code> variable. This is a special key used for services outside of the standard Django login to be able to push data into the system. The key will be used in the scripts and in the headers for pushing data into the system. Copy the value from that file when running the below script against a local instance. When running against a production deployment, you'll need to acquire an API key for that instance and use that instead.</p>"},{"location":"DevDocs/IngestingData/#loading-ground-truth-data","title":"Loading Ground Truth Data","text":"<p>Within the <code>scripts</code> directory is a python script named <code>loadGroundTruth.py</code>.  This file can be used in conjunction with the ground truth annotations located in the annotation Repo: Annotation Repo Running a command like:</p> <pre><code>python loadGroundTruth.py ~/AnnotationRepoLocation --rgd-api-key {RDWATCH_MODEL_RUN_API_KEY}\n</code></pre> <p>will load all of the annotations for the ground truth along with the regions.  using <code>--skip_regions</code> will skip loading the region geometry</p>"},{"location":"DevDocs/IngestingData/#loading-single-model-runs","title":"Loading Single Model Runs","text":"<p>Within the <code>scripts</code> directory is a python script named <code>loadModelRuns.py</code>. This can be used to load a folder filled with geojson data into the system by using a command like:</p> <pre><code>python loadModelRuns.py 'KR_0001' \"./site_models/KR_R001_*.geojson\" --title Test_Eval_12 --performer_shortcode 'KIT' --eval_num 12 --eval_run_num 0 --rgd-api-key {RDWATCH_MODEL_RUN_API_KEY}\n</code></pre> <p>By default, this command uploads to the RGD server hosted at <code>http://localhost:8000</code>, but that can be changed by passing an optional <code>--rgd-endpoint</code> argument to the command. Be sure that the system is up and running before running the commands. The above command will load the data that matches the provided glob expression and give it the title 'Test_Eval_12'. The <code>eval_num</code> and <code>eval_run_num</code> aren't required unless the scoring database is going to be connected to the system.</p>"},{"location":"DevDocs/IngestingData/#scoring","title":"Scoring","text":"<p>The Metrics and Test Framework can be used in addition with RGD to display scores from results. In development mode a scoring Database is automatically initialized at URI: <code>postgresql+psycopg2://scoring:secretkey@localhost:5433/scoring</code></p> <p>To score data: - Clone the Metrics and Test Framework repo. - In the Metrics and Test Framework repo:   - Copy the <code>alembic_example.ini</code> to <code>alembic.ini</code> and set the <code>sqlalchemy.url = postgresql+psycopg2://scoring:secretkey@localhost:5433/scoring</code>   - Run <code>pip install -e .</code> to install the metrics-and-test-framework package   - Run <code>alembic upgrade head</code> to initialize the scoring database schema   - Execute the scoring code from inside the metrics and test framework: <pre><code>  python -m iarpa_smart_metrics.run_evaluation \\\n               --roi KR_R001 \\\n               --gt_dir ../annotations/site_models/ \\\n               --rm_path ../KR_R001/region_model.geojson \\\n               --sm_dir ../KR_R001/site_models/ \\\n               --output_dir ../KR_R001/output \\\n               --eval_num 12 \\\n               --eval_run_num 0 \\\n               --performer kit \\\n               --no-viz \\\n               --no-viz-detection-table \\\n               --no-viz-comparison-table \\\n               --no-viz-associate-metrics \\\n               --no-viz-activity-metrics \\\n               --sequestered_id KR_R001 \\\n               --db_conn_str postgresql+psycopg2://scoring:secretkey@localhost:5433/scoring\n</code></pre> - the <code>rm_path</code> and <code>sm_dir</code> should be your test annotations. - ground truth annotations can be retrieved from the Annotation Repo - be sure to set the <code>val_num</code> and <code>eval_run_num</code> and remember them when ingesting data into RGD. The <code>region</code>, <code>eval_num</code>, <code>eval_run_num</code> and <code>performer</code> are used to connect data loaded in RGD to the scoring data. - For Scoring data with points execute the following command: <pre><code>  python -m iarpa_smart_metrics.run_evaluation \\\n               --roi KR_R002 \\\n               --output_dir ../KR_R002_point_scoring/output \\\n               --eval_num 24 \\\n               --eval_run_num 1 \\\n               --performer kit \\\n               --no-viz \\\n               --no-viz-detection-table \\\n               --no-viz-comparison-table \\\n               --no-viz-associate-metrics \\\n               --no-viz-activity-metrics \\\n               --sequestered_id KR_R002 \\\n               --db_conn_str postgresql+psycopg2://scoring:secretkey@localhost:5433/scoring \\\n               --rm_path ../KR_R002/region_model.geojson \\\n               --sm_dir ../KR_R002/site_models/ \\\n               --gt_points_file ../annotations/supplemental_data/point_based_annotations.geojson\n</code></pre></p>"},{"location":"DevDocs/IngestingData/#manually-loading","title":"Manually Loading","text":""},{"location":"DevDocs/IngestingData/#create-a-model-run","title":"Create a <code>model-run</code>","text":"<p>A <code>model-run</code> is a grouping of site evaluations. This grouping can contain outputs of a machine learning model, ground truth outputs, etc. In order to ingest data, it must be associated with a <code>model-run</code>.</p> <p>You can view and create <code>model-runs</code> on the <code>/api/model-runs</code> endpoint.</p> <ul> <li>GET <code>/api/model-runs</code>: list all</li> <li>GET <code>/api/model-runs/{id}</code>: retrieve a single instance</li> <li>POST <code>/api/model-runs</code>: create an instance</li> </ul> <p>Prior to creating a model run, you may have to create a performer to associate it with. RD-WATCH comes pre-configured with some performers by default; you can send a request to the <code>/api/performers/</code> endpoint to check the available performers:</p> <pre><code>$ curl https://some.rgd.host/api/performers/\n</code></pre> <p>To create a new performer, you can make a separate POST request to the API. The following JSON is an example of data to be used to create a <code>performer</code>:</p> <pre><code>// performer.json\n{\n  \"team_name\": \"Kitware\",\n  \"short_code\": \"KIT\"\n}\n</code></pre> <p>To create this performer:</p> <pre><code>$ curl \\\n    -H \"Content-Type: application/json\" \\\n    -H \"X-RDWATCH-API-KEY: {RDWATCH_MODEL_RUN_API_KEY}\" \\\n    -X POST \\\n    -d @performer.json \\\n    https://some.rgd.host/api/performers/\n</code></pre> <p>Once you've ensured the desired performer exists, you can create a model run. The following JSON is an example of data to be used to create a <code>model-run</code>:</p> <pre><code>//model-run.json\n{\n  // must be a valid performer short-code\n  \"performer\": \"KIT\",\n  // must be a valid region string\n  \"region\": \"KW_R001\",\n  // a human-readable title\n  \"title\": \"Ingestion 3.2\",\n  // number of hours after upload when this model run should be automatically deleted.\n  // exclude this field if you want the model run to remain in the database permanently.\n  \"expiration_time\": 2,\n  // can be any JSON that helps keep track of what this model-run is\n  \"parameters\": {\n    \"any\": \"data\"\n  }\n}\n</code></pre> <p>To create this <code>model-run</code>:</p> <pre><code>$ curl \\\n    -H \"Content-Type: application/json\" \\\n    -H \"X-RDWATCH-API-KEY: {RDWATCH_MODEL_RUN_API_KEY}\" \\\n    -X POST \\\n    -d @model-run.json \\\n    https://some.rgd.host/api/model-runs/\n</code></pre> <p>You'll get the newly created <code>model-run</code> as a response:</p> <pre><code>{\n  \"id\": 12,\n  \"title\": \"Ingestion 3.2\",\n  \"region\": null,\n  \"performer\": {\n    \"id\": 7,\n    \"team_name\": \"Kitware\",\n    \"short_code\": \"KIT\"\n  },\n  \"parameters\": {\n    \"any\": \"data\"\n  },\n  \"numsites\": 0,\n  \"score\": null,\n  \"timestamp\": null,\n  \"timerange\": null,\n  \"bbox\": null,\n  \"created\": \"&lt;creation_datetime&gt;\",\n  \"expiration_time\": \"01:00:00\"\n}\n</code></pre>"},{"location":"DevDocs/IngestingData/#add-data-to-a-model-run","title":"Add data to a <code>model-run</code>","text":"<p>You can <code>POST</code> a Site Model Specification JSON to the endpoint <code>/api/model-runs/{id}/site-model/</code> or a Region Model Specification JSON to the endpoint <code>/api/model-runs/{id}/region-model/</code>.</p> <p>Following the above example, lets POST a Site Model Specification JSON file in the current working directory named \"site.json\" to the newly created <code>model-run</code>:</p> <pre><code>$ curl \\\n    -H \"Content-Type: application/json\" \\\n    -H \"X-RDWATCH-API-KEY: {RDWATCH_MODEL_RUN_API_KEY}\" \\\n    -X POST \\\n    -d @site.json \\\n    https://some.rgd.host/api/model-runs/12/site-model/\n</code></pre> <p>Ensure the JSON correctly validates against the Site Model Specification. While many validation errors are reported, a malformed JSON will not report helpful errors. For example, the specification mandates each 'Observation' feature must include a <code>current_phase</code> string, but some data in the wild is not compliant with this and instead includes <code>\"current_phase\": null</code>. This is a malformed JSON and will not able to be parsed.</p>"},{"location":"DevDocs/SatelliteImages/","title":"Satellite Image Retrieval","text":"<p>The RDWATCH system relies on a STAC API to query for visual satellite images stored in the COG (Cloud Optimized GeoTIFF) format.  After searching for these images based on a spatial and temporal filter it will download them for display.  These COG files are stored in S3 buckets and the STAC API provides the S3 URL to the file.</p>"},{"location":"DevDocs/SatelliteImages/#collections","title":"Collections","text":"<p>RD-WATCH will query the STAC server for 4 sources:</p> <ul> <li>WV: WorldView</li> <li>S2: Sentinel 2</li> <li>L8: Landsat 8</li> <li>PL: Planet Labs</li> </ul> <p>WorldView is treated differently from the rest of Satellite Sources.  WorldView can be pansharpened if there exists additional imagery data.  This allows a higher resolution image to be displayed when compared to the other Sources.</p> <p>There is an environment variable <code>RDWATCH_ACCENTURE_VERSION</code> that is used to determine the collections that are searched when querying the STAC server.</p>"},{"location":"DevDocs/SatelliteImages/#code-layout","title":"Code Layout","text":"<p>The pystac_client library is utilized to make queries to the STAC server.</p> <p>Within the ./rdwatch/core/utils directory contains helper tools for Querying the STAC server and processing the resulting images.</p> <p>In the root of that folder is a <code>stac_search.py</code> which is used for S2,L8,PL image sources. The Collections to search for images are specified here</p> <pre><code>if settings.ACCENTURE_VERSION is not None:\n    COLLECTIONS['S2'].append(f'ta1-s2-acc-{settings.ACCENTURE_VERSION}')\n    COLLECTIONS['L8'].append(f'ta1-ls-acc-{settings.ACCENTURE_VERSION}')\n    COLLECTIONS['PL'].append(f'ta1-pd-acc-{settings.ACCENTURE_VERSION}')\n</code></pre>"},{"location":"DevDocs/SatelliteImages/#querying-stac","title":"Querying STAC","text":"<p>Within ./rdwatch/core/utils/satellite_bands.py file is the main function <code>get_bands</code>.  This function performs a STAC Query for a time range and a bounding box utilizing pystac.  The results are typically verbose so it is paginated with 100 results at a time.  It iterates over these times and returns all 'visual' images that match the query.  If the results match a visual band image they are returned as a <code>Band</code> class.  This <code>Band</code> class contains the following information:</p> <ul> <li>constellation: source of image (S2, L8, PL)</li> <li>spectrum: Information about the spectrum the band captures (\u03bcm)</li> <li>level: processing level</li> <li>timestamp: date of the satellite image</li> <li>bbox: bounding box associated with the image</li> <li>uri: Typically contains the S3 URL for the COG that contains the image</li> <li>cloudcover: optional value that will extract metadata to indicate the amount of cloud cover in the image</li> <li>collection: The collection this image was retrieved from</li> </ul>"},{"location":"DevDocs/SatelliteImages/#worldview-differences","title":"WorldView Differences","text":"<p>Within the ./rdwatch/core/utils folder there is a worldview_processed folder. It contains tools to create a pansharpened version of worldview images by downloading extra data.</p> <p>Instead of having a <code>Band</code> class for worldview there is a <code>WorldViewCapture</code> class in the base and a <code>WorldViewProcessedCapture</code>. The older base worldview folder will probably be removed as deprecated</p> <p><code>WorldViewProcessedCapture</code> is similar to the <code>Band</code> class but contains an optional <code>panuri</code> property to indicate an additional S3 location of the extra image to create a pansharpened image.</p> <p>the <code>get_captures</code> function in worldview_process/satellite_captures.py is similar to <code>get_bands</code> except there is a secondary process to attempt to find the <code>panuri</code> if available.</p>"},{"location":"DevDocs/SatelliteImages/#pansharpening","title":"Pansharpening","text":"<p>For worldview if there is a secondary panchromatic image found it will use the riotiler <code>pansharpening_brovy</code> function to increase the resolution of the image.</p>"},{"location":"DevDocs/SatelliteImages/#region-satellite-images","title":"Region Satellite Images","text":"<p>When viewing an entire region images can be turned on for the wole region.  It defaults to S2 as the source but WV can also be used. It follows the following process:</p> <ol> <li>A search for the region bounding box and a time range of 2010 to now will be search for the source images (either S2 or WV)</li> <li>After a list of images are found the client is provided with this list.</li> <li>When the satellite image is turned on the client will request the image closest to the current time in the slider.</li> <li>This then uses the image list to grab the URI for this image directly and use it for serving tiles.  The URI is sent to the back-end along with the x/y/z tile.  The riotiler then uses range requests to S3 to get the requested tile from S3 and provide it to the client. This can be seen <code>raster_tile.py</code> file for both the default <code>utils</code> and the <code>worldview_processed</code> folders.</li> </ol> <p>This process can be a bit slow when switching between satellite images.  Once an image is loaded it is cached so subsequent loads become faster but the caching isn't that large for the system.</p>"},{"location":"DevDocs/SatelliteImages/#site-satellite-image-chipping","title":"Site Satellite Image Chipping","text":"<p>Instead of downloading and using a tile server to view images for a whole region there is a task (in each App: core/scoring) that will chip/crop the images for individual sites and save them in a Object Store like S3/MinIO.</p> <p>Within (core/scoring)/tasks/init.py there are two functions called <code>generate_site_images_for_evaluation_run</code> and <code>generate_site_images</code>.  The <code>generatie_site_images_for_evaluation_run</code> calls <code>generate_site_images</code> for each site in a Model Run.  The core function that is eventually called is <code>get_siteobservations_images</code>.  This does the process of STAC Querying for images, processing them and eventually creating chips that are loaded into S3/MinIO.</p>"},{"location":"DevDocs/SatelliteImages/#image-chipping-parameters","title":"Image Chipping Parameters","text":"<ul> <li>site_id: UUID4 - The UUID for the Site to download</li> <li>constellation:=['WV'] - Watch satellite image sources to download.  Can be WV, S2, L8, PL or any combination</li> <li>force=False - Forces re-downloading images.  Useful if you change the filters (overrideDates, dayRange, noData) or if you believe the STAC Query has updated since last time you downloading images.</li> <li>dayRange=14 - S2, L8, PL imagery can have dense temporal images.  I.E there may be 5-6 pictures in a week and the changes between them aren't significant.  This parameter will prevent images from downloading if an image already exists in the dayRange.</li> <li>noData=50 - Filter to remove images that report having &gt; noData% of noData in them.  It's intended to remove majority black images from the images downloaded.</li> <li>overrideDates: None | list[datetime, datetime] = None - if set to <code>None</code> it will utilize the site time range for downloading images +/- 30 days to add a buffer.  If the site time range is null it will use 20130101 to the present time.  The overrideDates can be used to extend or reduce the time range when downloading images.</li> <li>scale: Literal['default', 'bits'] | list[int] = 'default' - THe image bit scaling for the brightness levels can be adjusted herre.  The Default scaling is 0-10,000.  The <code>list[int]</code> allows for two custom values.  The <code>bits</code> option will use the 2% lows and 98% highs to adjust the scaling.</li> <li>bboxScale: float = BboxScaleDefault - a number that will be used to scale up the boundingbox of the area around the site downloaded.  I.E. a value of 1.2 will ad 20% to the bounding box of polygon when downloading the image.  If the site image source is now WorldView (WV) it will estimate the real world size and if the height or width are under 1000 meters it will add whatever is needed to get the size of the bbox to 1000 meters.  This is done because of the lower resolution of S2,L8,PL.  The more context helps identifying features in the image.</li> </ul>"},{"location":"UserGuide/LayerManager/","title":"Layer Manager","text":"<p>The layer manager is located at the top of the map.  It is a series of buttons that allow for toggling on/off different layers as well as adding regions/sites/observations in additional modes.</p>"},{"location":"UserGuide/LayerManager/#ground-truth","title":"Ground Truth","text":"<p>Both the Site and Site Observation buttons will contain and option to toggle on/off the Ground Truth.  For the RDWATCH database the ground truth is determined by loading up the latest GroundTruth tagged model run for that specific Region.  Using the Scoring Database it will utilize the GroundTruth that the model run was scored against.  The toggling of GroundTruth will only be enabled for both instances if GroundTruth is found for the region or model run.</p>"},{"location":"UserGuide/LayerManager/#site-observations-sites","title":"Site Observations / Sites","text":""},{"location":"UserGuide/LayerManager/#site-observations","title":"Site Observations","text":"<p>This is the lowest level of polygons in the RDWATCH system.  A Site Observation is a Polygon associated with a specific instance in time.  Clicking on the button will toggle on a selected Model Run's Site Observations and associated Ground Truth Observations if they are found.  Hovering over the Site Observation will allow for toggling on/off either the model run site observations or the ground truth obsersvations individually.</p>"},{"location":"UserGuide/LayerManager/#sites","title":"Sites","text":"<p>Everything mentioned above is also applicable for sites.  Sites are different because they are a polygon that are associated with a Date Range instead of a specific date.</p>"},{"location":"UserGuide/LayerManager/#time-limits","title":"Time Limits","text":"<p>Sites have an additional option called Time Limits.  By default the Site display will persist a site for all time after it is initially displayed.  I.E if the global time slider is at date 20240704 and a Site has a time range of 20200101-20220101 it will display this site.  Turning on Time Limits will hide a site if the current time is outside of the time range of the site.</p>"},{"location":"UserGuide/LayerManager/#region","title":"Region","text":"<p>Toggles on/off the polygon Region if it is available</p>"},{"location":"UserGuide/LayerManager/#region-editing-rdwatch-database","title":"Region Editing (RDWATCH Database)","text":"<ul> <li>Region Deletion: If you are the owner of a custom user region you can delete the region.  ONLY IF the region doesn't have any associated model runs with it.</li> <li>Download Region: Downloads the GeoJSON for the Region</li> <li>Add Region:  Allows for adding a custom Region by a user.  The region can be drawn by the user and then given a unique name.  This region can be used in the future to add sites or possible run SMARTFLOW on a region in the future.  Regions that are generated by users can be set to public so everyone can see it, or private to prevent other users from seeing the region.</li> </ul>"},{"location":"UserGuide/LayerManager/#scoring-scoring-database","title":"Scoring (Scoring Database)","text":"<p>While using the Scoring Database two additional views can be displayed:</p> <ul> <li>Simple: A simple view of the scoring results. When this view is turned on, all other layers are disabled.  The Map Legend will update to indicate what colors mean in this mode.</li> <li>Detailed: A simple view of the scoring results. When this view is turned on, all other layers are disabled.  The Map Legend will update to indicate what colors mean in this mode.</li> </ul>"},{"location":"UserGuide/LeftSidePanel/","title":"Model Run List (Left Side Panel)","text":""},{"location":"UserGuide/LeftSidePanel/#mode-selection","title":"Mode Selection","text":"<p>Select between Analyst and Annotator Mode. If the database is not RDWATCH it will display that the Source is Scoring.  The Database selection is persistent so reloading the page won't reset the source.  The source database can be set in the Settings.</p>"},{"location":"UserGuide/LeftSidePanel/#timeline-slider","title":"Timeline Slider","text":"<p>The Model Runs contain Sites and Site Observations that vary over time.  This time slider is a global setting that indicates the current time selection so the proper Site Observations and Satellite images are displayed.</p> <p>The Timeline Slider start/end date are set auomatically based on the list of model runs being displayed, or the model runs that are selected.  Any other tools that adjust the current time will be reflected in this global time slider.</p>"},{"location":"UserGuide/LeftSidePanel/#global-mapmodel-run-settings","title":"Global Map/Model Run Settings","text":"<p>There is a row of icons that are used to adjust settings in the system.</p> <ul> <li> Base Map Visibility: Turns on/off the base map (roads, boundaries, land vs water).  This is useful to create a screenshot without giving spatial clues as to the location of the polygons being visualized.</li> <li> Satellite Images: This button will download and cache the satellite timestamps initially and then allow toggling on/off region base satellite images.  The first time this is clicked there is a warning because the system will query the STAC API to find all satellite images for the region during the time period currently displayed in the Time Slider.  After this is complete a display of the number of Satellite Images will be displayed next to the Number of Model Runs below the ModelRun filter.  If there are images found the icon will change to  indicating that the satellite image can be turned on.  Once a satellite image is turned on the location where the number of satellite images were displayed will change to the closest timestamp of satellite image that matches the current global time set in the Time Slider</li> <li> Format Text: This turns on text status labels for the Site and Site Observations in the Map.  It is disabled by default because the density of labels can make it difficult to see the polygons.</li> <li> Map Legend: Toggles on/off the map legend.  The map legend changes based on the type of visible annotations</li> <li> Ground Truth: By default the ModelRun list only contains user runs.  This will show all of the GroundTruth Model runs.  GroundTruth model runs are indicated as GroundTruth when they are ingested into RDWATCH.  GroundTruth Model Runs, Sites and Site Observations are all indicated by the following icon: </li> <li>:material-settings:== Settings: Opens the Settings panel to adjust settings for the system.  See the Settings section to get more information</li> </ul>"},{"location":"UserGuide/LeftSidePanel/#modelrun-filters","title":"ModelRun Filters","text":"<ul> <li>Performer Filter: this will filter model runs based on the performer</li> <li>Region Filter: filters model runs by their associated region.  Regions that are user created and that are public will be included at the top of the list.  All other Regions will be in alphebetical order.  The region filter will be added to the URL and can be copied and pasted.  If pasted into a browser it will open with the filter pre-selected.</li> </ul>"},{"location":"UserGuide/LeftSidePanel/#scoring-filters","title":"Scoring Filters","text":"<p>When connected to the Scoring Database there are additional filters that are displayed</p> <ul> <li>Mode Filter: Filters the scoring results based on modes (batch or incremental)</li> <li>Evaluation Filter: When scoring a model run they are all tied to an Evaluation Number.  This filter will adjust the results base don this value.</li> </ul>"},{"location":"UserGuide/LeftSidePanel/#model-run-information","title":"Model Run Information","text":"<p>Directly below the filters is small area that includes two pieces of information</p> <p>-# of Model Runs - A small tag that indicates the number of model runs that the current filter shows -# of SatelliteImages / Current Satellite Image Timestamp - If the satellite images are turned on or if there are cached a list of a satellite images this will display either the total number of satellite images found for the region.  If the image is currently turned on it will display the current timestamp for the satellite image.</p>"},{"location":"UserGuide/LeftSidePanel/#model-run-card","title":"Model Run Card","text":"<p>Each model run card in the list can be selected by either clicking on the card or the checkbox for the card.  Once clicked on, the camera will zoom to the region for the model run and indicate it is selected by filling in the checkbox and highlight the model run card.</p>"},{"location":"UserGuide/LeftSidePanel/#model-run-card-information","title":"Model Run Card Information","text":"<ul> <li>Title: a descriptive title for the model run is located at the top</li> <li>Region: Associated region for the model run.</li> <li>Date Coverage: Analyzes the Sites in the listing and displays the Date Coverage for the Model Run</li> <li> <p>Last Updated: The timestamp of the model run being added or updated</p> </li> <li> <p>Model Run TimeSlider: A slider that is bound to the start/end date based on the Date Coverage.  When moved this will adjust the global time slider.</p> </li> <li> <p> Site Number: Number of Sites in the Model Run</p> </li> <li> Average Score:  Indication of the average score of the sites in the Model Run</li> <li>Scoring Database Only<ul> <li> Batch Mode: Using scoring database this indicates batch mode</li> <li>:material--trending-up:: ?Using scoring database this indicates incremental mode</li> </ul> </li> </ul>"},{"location":"UserGuide/LeftSidePanel/#model-run-actions","title":"Model Run Actions","text":"<ul> <li>RDWATCH Database Only<ul> <li> Download GeoJSON:  Downloads a Zip file that contains all of the geoJSON for the sites that are displayed.</li> </ul> </li> <li> Satellite Image Downloading:  Opens a dialog to begin downloading Satellite Images for all of the Sites in the model run.</li> </ul>"},{"location":"UserGuide/UsingRDWatch/","title":"Using RDWATCH","text":"<p>RDWATCH has the two main modes: Analyst and Annotator, as well as either being connected to the RDWATCH or Scoring database.  While there are these different modes, most of the interface is shared with minor changes between the modes and the source database.  This page will give a high level overview of the main UI elements that are shared.</p>"},{"location":"UserGuide/UsingRDWatch/#model-run-list-left-side-panel","title":"Model Run List (Left Side Panel)","text":"<p>The Left Side panel contains tools for selecting modes, adjusting the global Timeline, Filtering Model Runs and providing a list of Model Runs to select.</p>"},{"location":"UserGuide/UsingRDWatch/#layer-manager","title":"Layer Manager","text":"<p>The LayerManager manages what polygons are displayed on the map and filters based on time/coloring or other items.</p>"},{"location":"UserGuide/Vocabulary/","title":"Vocabulary and Terms","text":"<p>RDWATCH and the underlying SMART project have numerous Domain specific language and data structures.  This page helps define common terms.</p>"},{"location":"UserGuide/Vocabulary/#background","title":"Background","text":"<p>RDWATCH is meant to display geometry (polygons/points) in a geospatial and temporal context with annotations on an interactive map.  Geometry can exist for a single point in time (SiteObservation) or for a time interval (Site).  The original purpose for RDWATCH was to compare Construction states (Site Preparation, Active Construction, Post Construction) for polygons with a GroundTruth.  This was to inspect the accuracy of algorithms that are meant to detect these states from Satellite Images.</p>"},{"location":"UserGuide/Vocabulary/#analyst-mode","title":"Analyst Mode","text":"<p>This mode is made for reviewing the results of algorithms and comparing them with ground truth</p>"},{"location":"UserGuide/Vocabulary/#annotator-mode","title":"Annotator Mode","text":"<p>This mode allows for modification of Sites and Site Observations.  This includes modifying the Status, Time/Time Range or the Polygon.  These sites/site Observations can be approved or rejected and the geoJSON can be exported.</p>"},{"location":"UserGuide/Vocabulary/#data-hierarchy","title":"Data Hierarchy","text":"<ul> <li>Region: A polygon indicating an area on the globe where Model Runs can be located</li> <li>Performer: A Name for an organization/individual/group that creates a Model Run.</li> <li>GroundTruth: A Model Run in a Region that contains Groundtruth Sites and Site Observations for comparison with non GroundTruth Model Runs</li> <li>Model Run: a collection of Sites that contain Site Observations.  ModelRuns are identified with a title and have a Region as well as a Performer.  Model Runs are filtered by their Region, Performer or if they are GroundTruth</li> <li>Site: A Point or Polygon that extends over a Range of time.  The Site also has it's own State annotation that indicates information about the Site (positive, negative, ignore, syse,_conmfirmed).  It has a start date and an end date.  These dates can be <code>null</code> if the Start Date and End Date are unknown.  These dates are used in RDWATCH to filter and display the Sites.  A Site is a parent to zero or more Site Observations.</li> <li>Site Observation:  A Point or Polygon that is associated with a specific point in time.  It has a date as well as a state (Site Preparation, Active Construction, Post Construction).  A Site Observation is always associated with a Site.</li> </ul>"},{"location":"UserGuide/Vocabulary/#satellite-images","title":"Satellite Images","text":"<p>The RDWATCH system relies on a STAC API to query for visual satellite images stored in the COG (Cloud Optimized GeoTIFF) format.  After searching for these images based on a spatial and temporal filter it will download them for display.  These COG files are stored in S3 buckets and the STAC API provides the S3 URL to the file.</p>"},{"location":"UserGuide/Vocabulary/#region-satellite-mode","title":"Region Satellite Mode","text":"<p>This mode will convert a specificif COG image into a tile server so that a whole region can be displayed at once.  This defaults to utilizing Sentinel 2 (S2) for the image source.  In the settings it can be modified to WorldView (WV) but the download would take more time.</p>"},{"location":"UserGuide/Vocabulary/#satellite-site-chipping","title":"Satellite Site Chipping","text":"<p>There is an option to download individual images around the region of a Site Polygon.  This still uses the STAC API to get the COG files, but then takes those files and crops them to an area around the polygon and stores them in MinIO/S3 for faster access when compared to accessing a COG.</p>"},{"location":"UserGuide/Vocabulary/#satellite-sources","title":"Satellite Sources","text":"<ul> <li>Simple Sources<ul> <li>S2: Sentinel 2</li> <li>L8: LandSat 8</li> <li>PL: PlanetLabs</li> <li>These simple sources are lower resolution and may have a higher frequency of images across a given time range.  This is why in the download settings there is a Day Limit that can be used to limit it so only one image is downloaded every X days.</li> </ul> </li> <li>PanSharpened<ul> <li>WV: WorldView</li> <li>Pansharpening is a post process that occurs if there are multiple images that can be referenced.  This combines the images and creates a higher resolution image.</li> <li>The day limits aren't applied to WorldView images because they aren't as frequent as the other sources and having the higher resolution is beneficial.</li> </ul> </li> </ul>"},{"location":"UserGuide/Vocabulary/#future-smartflow-documentation","title":"Future SmartFlow Documentation","text":""}]}